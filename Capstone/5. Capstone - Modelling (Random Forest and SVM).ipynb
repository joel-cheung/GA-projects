{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "705a617f",
   "metadata": {},
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741d8524",
   "metadata": {},
   "source": [
    "Twitter is a micro-blogging social media platform with 217.5 million daily active users globally. With 500 million new tweets (posts) daily, the topics of these tweets varies widely – k-pop, politics, financial news… you name it! Individuals use it for news, entertainment, and discussions, while corporations use them to as a marketing tool to reach out to a wide audience. Given the freedom Twitter accords to its user, Twitter can provide a conducive environment for productive discourse, but this freedom can also be abused, manifesting in the forms of racism and sexism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4cfa85",
   "metadata": {},
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ca1cbd",
   "metadata": {},
   "source": [
    "With Twitter’s significant income stream coming from advertisers, it is imperative that Twitter keeps a substantial user base. On the other hand, Twitter should maintain a safe space for users and provide some level of checks for the tweets the users put out into the public space, and the first step would be to identify tweets that espouse racist or sexist ideologies, and then Twitter can direct the users to appropriate sources of information where users can learn more about the community that they offend or their subconscious biases so they will be more aware of their racist/sexist tendencies. Thus, to balance, Twitter has to be accurate in filtering inappropriate tweets from innocuous ones, and the kind of inappropriateness of flagged tweets (tag - racist or sexist).\n",
    "\n",
    "F1-scores will be the primary metric as it looks at both precision and recall, each looking at false positives (FPs) and false negatives (FNs) respectively, and is a popular metric for imbalanced data as is the case with the dataset used.\n",
    "\n",
    "For the purpose of explanation, racist tweets are used as the ‘positive’ case.\n",
    "\n",
    "In this context, FPs are the cases where the model erroneously flags out tweets as racist when the tweet is actually innocuous/sexist. FNs are cases where the model erroneously flags out tweets as innocuous/sexist but the tweets are actually racist.\n",
    "\n",
    "Thus, higher F1-scores are preferred."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a89ba68",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "95dce205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For NLP data cleaning and preprocessing\n",
    "import re, string, nltk, itertools\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "# Pickle to save model\n",
    "import pickle\n",
    "\n",
    "# For NLP Machine Learning processes\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "# Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "\n",
    "# Support Vector Machine\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# PyTorch LSTM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# Tokenization for LSTM\n",
    "from collections import Counter\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Transformers library for BERT\n",
    "import transformers\n",
    "from transformers import BertModel\n",
    "from transformers import BertTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, plot_roc_curve, RocCurveDisplay\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e7e3229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seed for reproducibility\n",
    "import random\n",
    "\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2b54d6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing display settings\n",
    "pd.set_option('display.max_row', 100)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aadea0",
   "metadata": {},
   "source": [
    "# Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cff682b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter = pd.read_csv('../Capstone/data/twitter_char_4_gram_lemm_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3b0802e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Annotation', 'Text_lemm_char_4_gram'], dtype='object')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "575f2120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Annotation</th>\n",
       "      <th>Text_lemm_char_4_gram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>read cont onte ntex text extn xtno chan hang ange mean eani anin ning hist isto stor tory isla slam lami amic slav lave aver very</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>idio diot clai laim peop eopl ople stop beco ecom come terr erro rror rori oris rist make terr erro rror rori oris rist isla slam lami amic mica ical call ally brai rain dead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>call sexi exis xist auto plac lace woul ould rath athe ther talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>wron rong foll ollo llow exam xamp ampl mple moha oham hamm amme mmed qura uran exac xact actl ctly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>saud audi prea reac each ache cher tort ortu rtur ture five year earo arol rold daug augh ught ghte hter deat eath rele elea leas ease</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Annotation  \\\n",
       "0           0   \n",
       "1           0   \n",
       "2           1   \n",
       "3           2   \n",
       "4           0   \n",
       "\n",
       "                                                                                                                                                            Text_lemm_char_4_gram  \n",
       "0                                               read cont onte ntex text extn xtno chan hang ange mean eani anin ning hist isto stor tory isla slam lami amic slav lave aver very  \n",
       "1  idio diot clai laim peop eopl ople stop beco ecom come terr erro rror rori oris rist make terr erro rror rori oris rist isla slam lami amic mica ical call ally brai rain dead  \n",
       "2                                                                                                                call sexi exis xist auto plac lace woul ould rath athe ther talk  \n",
       "3                                                                             wron rong foll ollo llow exam xamp ampl mple moha oham hamm amme mmed qura uran exac xact actl ctly  \n",
       "4                                          saud audi prea reac each ache cher tort ortu rtur ture five year earo arol rold daug augh ught ghte hter deat eath rele elea leas ease  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631082f8",
   "metadata": {},
   "source": [
    "# Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "053c1ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the creating the X and Y columns for the character 4-gram based on lemmatized text dataset\n",
    "X, y = twitter['Text_lemm_char_4_gram'], twitter['Annotation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f5259cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conducting train/test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify = y, random_state = seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c51fb9b",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4464f9d6",
   "metadata": {},
   "source": [
    "### Random Forest Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bf9c3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a pipeline:\n",
    "# 1. Instantiating CountVectorizer\n",
    "# 2. SMOTE sampling - due to imbalance of classes\n",
    "# 3. Random Forest\n",
    "\n",
    "pipe_rf = Pipeline([\n",
    "        ('cvec', CountVectorizer()),\n",
    "        ('sampling', SMOTE()),\n",
    "        ('rf', RandomForestClassifier())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "474f2cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up hyperparameters tuning                    \n",
    "pipe_rf_params = {\n",
    "    'cvec__max_features': [2_000, 3_000, 4_000],       \n",
    "    'cvec__min_df': [3, 4, 5],                           \n",
    "    'cvec__max_df': [0.5, 0.6, 0.7],                           \n",
    "    'cvec__ngram_range': [(1,1)],\n",
    "    'rf__n_estimators': [50, 70, 90],\n",
    "    # To match the metric used for the BERT model\n",
    "    'rf__criterion': ['entropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e898f2a",
   "metadata": {},
   "source": [
    "### GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9da0c165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs_rf = GridSearchCV(pipe_rf, \n",
    "                  param_grid = pipe_rf_params, # Parameters values we are searching over\n",
    "                  cv=5, # 5-fold cross-validation\n",
    "                 n_jobs = -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3e29526",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46 s\n",
      "Wall time: 57min 55s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;cvec&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;sampling&#x27;, SMOTE()),\n",
       "                                       (&#x27;rf&#x27;, RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;cvec__max_df&#x27;: [0.5, 0.6, 0.7],\n",
       "                         &#x27;cvec__max_features&#x27;: [2000, 3000, 4000],\n",
       "                         &#x27;cvec__min_df&#x27;: [3, 4, 5],\n",
       "                         &#x27;cvec__ngram_range&#x27;: [(1, 1)],\n",
       "                         &#x27;rf__criterion&#x27;: [&#x27;entropy&#x27;],\n",
       "                         &#x27;rf__n_estimators&#x27;: [50, 70, 90]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;cvec&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;sampling&#x27;, SMOTE()),\n",
       "                                       (&#x27;rf&#x27;, RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;cvec__max_df&#x27;: [0.5, 0.6, 0.7],\n",
       "                         &#x27;cvec__max_features&#x27;: [2000, 3000, 4000],\n",
       "                         &#x27;cvec__min_df&#x27;: [3, 4, 5],\n",
       "                         &#x27;cvec__ngram_range&#x27;: [(1, 1)],\n",
       "                         &#x27;rf__criterion&#x27;: [&#x27;entropy&#x27;],\n",
       "                         &#x27;rf__n_estimators&#x27;: [50, 70, 90]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;cvec&#x27;, CountVectorizer()), (&#x27;sampling&#x27;, SMOTE()),\n",
       "                (&#x27;rf&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('sampling', SMOTE()),\n",
       "                                       ('rf', RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.5, 0.6, 0.7],\n",
       "                         'cvec__max_features': [2000, 3000, 4000],\n",
       "                         'cvec__min_df': [3, 4, 5],\n",
       "                         'cvec__ngram_range': [(1, 1)],\n",
       "                         'rf__criterion': ['entropy'],\n",
       "                         'rf__n_estimators': [50, 70, 90]})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Fitting Random Forest model\n",
    "gs_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c6afbb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "rf_predictions = gs_rf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "614ab49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating F1 score of Random Forest model\n",
    "rf_f1_score = f1_score(y_val, rf_predictions, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a3ccdb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7286691209604766"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d81f39",
   "metadata": {},
   "source": [
    "The tuned Random Forest model has the F1 score of 0.728"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5d5c60",
   "metadata": {},
   "source": [
    "### Saving Tuned Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c21508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving\n",
    "pickle.dump(gs_rf, open(\"../Capstone/rf_model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "74b24150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading\n",
    "rf_model = pickle.load(open(\"../Capstone/rf_model.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3b3eeca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting tags on train set\n",
    "rf_model_pred = rf_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b50dde89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating f1-score on train set\n",
    "rf_train_f1 = f1_score(y_train, rf_model_pred, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c900dcb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9808416305860602"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_train_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa12a31",
   "metadata": {},
   "source": [
    "Given the large difference betweeen the f1 score on the train set (0.980) and the validation set (0.728), it can be observed that the random forest model overfits on the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f13636",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f8311703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a pipeline:\n",
    "# 1. Standard scaling\n",
    "# 2. SMOTE sampling\n",
    "# 3. SVM\n",
    "\n",
    "svm_pipe = Pipeline([\n",
    "        ('cvec', CountVectorizer()),\n",
    "        ('sampling', SMOTE(n_jobs = -1)),\n",
    "        ('svc', SVC())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "25705e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up hyperparameters tuning                  \n",
    "svm_params = {\n",
    "    'sampling__sampling_strategy': ['minority'],   \n",
    "    'sampling__k_neighbors': [3, 5],                  \n",
    "    'svc__gamma':['auto','scale'],                        \n",
    "    'svc__kernel':['linear'],     \n",
    "    'svc__random_state': [42],                    \n",
    "    'svc__probability' : [True],                                              \n",
    "    'svc__shrinking' : [True, False],                   \n",
    "    'svc__class_weight' : ['balanced'],           \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d396de1",
   "metadata": {},
   "source": [
    "### GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f043b895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV.\n",
    "gs_svm = GridSearchCV(svm_pipe, \n",
    "                  param_grid = svm_params, # Parameters values we are searching over\n",
    "                  cv=5, # 5-fold cross-validation\n",
    "                  n_jobs = -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ab11fb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4min 7s\n",
      "Wall time: 53min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Fitting the XGboost model\n",
    "svm_model = gs_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0784830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "svm_predictions = svm_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6e29b02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating F1 score of XGBoost model\n",
    "svm_f1_score = f1_score(y_val, svm_predictions, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "74239ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7496347637745211"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0243500e",
   "metadata": {},
   "source": [
    "The tuned SVM Model has a F1 score of 0.749"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a469662f",
   "metadata": {},
   "source": [
    "### Saving SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "135852ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving\n",
    "pickle.dump(svm_model, open(\"../Capstone/svm_model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "40604378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading\n",
    "svm_model = pickle.load(open(\"../Capstone/svm_model.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "15910ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting tags on train set\n",
    "svm_model_pred = svm_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9515c1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating f1-score on train set\n",
    "svm_train_f1 = f1_score(y_train, svm_model_pred, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a522ee9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9407568055256157"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_train_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb00165",
   "metadata": {},
   "source": [
    "Given the large difference betweeen the f1 score on the train set (0.940) and the validation set (0.749), it can be observed that the SVM model overfits on the training dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
