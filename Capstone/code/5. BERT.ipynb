{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa134a6d",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Capstone Project - Identifying Offensive Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd0128e",
   "metadata": {},
   "source": [
    "# Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2803edae",
   "metadata": {},
   "source": [
    "This is my capstone project for the General Assembly Data Science Immersive course.\n",
    "\n",
    "This is the fifth notebook of this project.\n",
    "\n",
    "In this notebook, the steps conducted are:\n",
    "\n",
    "    1. Modelling - Bidirectional Encoder Representations from Transformers (BERT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71309a2",
   "metadata": {},
   "source": [
    "**CONTENT WARNING: This project includes content that are sensitive and may be offensive to some viewers. These topics include mentions (many negative) and slurs of race, religion, and gender.**\n",
    "\n",
    "**NOTE: All text information that are used in this project are directly taken from the websites and do not reflect what I believe in. All tags (whether a tweet is racist/sexist, or not) are taken as is from the source.**\n",
    "\n",
    "For the purpose of this project, the offensive tweets of interest are ones that are racist and sexist. \n",
    "\n",
    "Racist tweets are defined as those that have antagonistic sentiments toward certain religious figures or individuals from a religious group, and/or individuals or groups from a certain race. Given the dataset 'classified_tweets' not separating the racist and sacrilegious/blasphemous (anti-religious) tweets, the 'racist' tag will be applied for both categories.\n",
    "\n",
    "Sexist tweets are defined as those that have misogynistic, homophobic, and/or transphobic sentiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705a617f",
   "metadata": {
    "id": "705a617f"
   },
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d37779",
   "metadata": {
    "id": "b4d37779"
   },
   "source": [
    "Twitter is a micro-blogging social media platform with 217.5 million daily active users globally. With 500 million new tweets (posts) daily, the topics of these tweets varies widely – k-pop, politics, financial news… you name it! Individuals use it for news, entertainment, and discussions, while corporations use them to as a marketing tool to reach out to a wide audience. Given the freedom Twitter accords to its user, Twitter can provide a conducive environment for productive discourse, but this freedom can also be abused, manifesting in the forms of racism and sexism. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4cfa85",
   "metadata": {
    "id": "5f4cfa85"
   },
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9149c8b2",
   "metadata": {
    "id": "9149c8b2"
   },
   "source": [
    "With Twitter’s significant income stream coming from advertisers, it is imperative that Twitter keeps a substantial user base. On the other hand, Twitter should maintain a safe space for users and provide some level of checks for the tweets the users put out into the public space, and the first step would be to identify tweets that espouse racist or sexist ideologies, and then Twitter can direct the users to appropriate sources of information where users can learn more about the community that they offend or their subconscious biases so they will be more aware of their racist/sexist tendencies. Thus, to balance, Twitter has to be accurate in filtering inappropriate tweets from innocuous ones, and the kind of inappropriateness of flagged tweets (tag - racist or sexist).\n",
    "\n",
    "F1-scores will be the primary metric as it looks at both precision and recall, each looking at false positives (FPs) and false negatives (FNs) respectively, and is a popular metric for imbalanced data as is the case with the dataset used.\n",
    "\n",
    "For the purpose of explanation, racist tweets are used as the ‘positive’ case.\n",
    "\n",
    "In this context, FPs are the cases where the model erroneously flags out tweets as racist when the tweet is actually innocuous/sexist. FNs are cases where the model erroneously flags out tweets as innocuous/sexist but the tweets are actually racist.\n",
    "\n",
    "There is a need to balance the identification of an offensive tweet when it is indeed offensive and the need to maintain a high level of user experience (something that would be jeopardized when the model erroneously flags innocuous tweets as offensive).\n",
    "\n",
    "Thus, higher F1-score is the preferred metric to assess model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a89ba68",
   "metadata": {
    "id": "7a89ba68"
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "XIrzpYGNznlE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XIrzpYGNznlE",
    "outputId": "7d5ae7d5-c240-40fb-c1b7-5424302410f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.21.2-py3-none-any.whl (4.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.7 MB 7.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
      "\u001b[K     |████████████████████████████████| 120 kB 74.1 MB/s \n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.6 MB 58.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.21.2\n"
     ]
    }
   ],
   "source": [
    "# Installing transformers library for BERT model \n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95dce205",
   "metadata": {
    "id": "95dce205"
   },
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For NLP data cleaning and preprocessing\n",
    "import re, string, nltk, itertools\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "# Pickle to save model\n",
    "import pickle\n",
    "\n",
    "# For showing time\n",
    "import time\n",
    "\n",
    "# For NLP Machine Learning processes\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "# Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# Transformers library for BERT\n",
    "import transformers\n",
    "from transformers import BertModel\n",
    "from transformers import BertTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, plot_roc_curve, RocCurveDisplay\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7e3229f",
   "metadata": {
    "id": "e7e3229f"
   },
   "outputs": [],
   "source": [
    "# Setting seed for reproducibility\n",
    "import random\n",
    "\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "torch.manual_seed(seed_value)\n",
    "torch.cuda.manual_seed_all(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b54d6dc",
   "metadata": {
    "id": "2b54d6dc"
   },
   "outputs": [],
   "source": [
    "# Changing display settings\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aadea0",
   "metadata": {
    "id": "e9aadea0"
   },
   "source": [
    "# Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hC4uBxaxAV6g",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hC4uBxaxAV6g",
    "outputId": "3006999e-1e2b-463a-d07b-ae8c308566db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Mounting drive to access dataset on Google Colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cff682b7",
   "metadata": {
    "id": "cff682b7"
   },
   "outputs": [],
   "source": [
    "# Importing dataset\n",
    "data = pd.read_csv('/content/drive/MyDrive/Capstone/data/data_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b0802e1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3b0802e1",
    "outputId": "5f457afb-0d28-4e19-ccac-0a95ce17c6ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tag', 'set', 'text'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "575f2120",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "575f2120",
    "outputId": "93a16afc-7cc3-434d-c592-a30464217721",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-611787be-0f03-4dc0-bae8-e30f5b8295c6\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>set</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>way insult direct man unflattering hat worn predominantly men meant ins…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>ordinary muslim idiot person like know make sure qur’an muslim nothing claim jihad come back talk feel offend worship cow exactly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>give buildup sweeden government idiotu behave like allrounder see reach god know many fake news u put brainsor many time u use hindu muslim cow even need spread hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>sure pot cooked hot mkr killerblondes abarmezh86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>christian part palestinian kill driven palestinian muslim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-611787be-0f03-4dc0-bae8-e30f5b8295c6')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-611787be-0f03-4dc0-bae8-e30f5b8295c6 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-611787be-0f03-4dc0-bae8-e30f5b8295c6');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   tag    set  \\\n",
       "0    2  train   \n",
       "1    1  train   \n",
       "2    1  train   \n",
       "3    0  train   \n",
       "4    1  train   \n",
       "\n",
       "                                                                                                                                                                    text  \n",
       "0                                                                                               way insult direct man unflattering hat worn predominantly men meant ins…  \n",
       "1                                      ordinary muslim idiot person like know make sure qur’an muslim nothing claim jihad come back talk feel offend worship cow exactly  \n",
       "2  give buildup sweeden government idiotu behave like allrounder see reach god know many fake news u put brainsor many time u use hindu muslim cow even need spread hate  \n",
       "3                                                                                                                       sure pot cooked hot mkr killerblondes abarmezh86  \n",
       "4                                                                                                              christian part palestinian kill driven palestinian muslim  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7014a0cb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7014a0cb",
    "outputId": "3e5e6479-f6fb-47ea-fd12-dc022ff8dfa9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34808, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f11df29",
   "metadata": {
    "id": "4f11df29"
   },
   "outputs": [],
   "source": [
    "tag = ['none', 'racism', 'sexism']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631082f8",
   "metadata": {
    "id": "631082f8"
   },
   "source": [
    "# Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "j8RSK_OQKt21",
   "metadata": {
    "id": "j8RSK_OQKt21"
   },
   "outputs": [],
   "source": [
    "# Split entire dataset into the two datasets\n",
    "# train dataset: cyberbullying_tweets.csv and test dataset: classified_tweets.csv\n",
    "train = data.loc[data['set'] == 'train']\n",
    "test = data.loc[data['set'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "053c1ae9",
   "metadata": {
    "id": "053c1ae9"
   },
   "outputs": [],
   "source": [
    "# Splitting the creating the X and Y columns\n",
    "X, y = train['text'].values, train['tag'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5259cee",
   "metadata": {
    "id": "f5259cee"
   },
   "outputs": [],
   "source": [
    "# Conducting train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06e84a6a",
   "metadata": {
    "id": "06e84a6a"
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, stratify=y_train, random_state=seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee056619",
   "metadata": {
    "id": "ee056619"
   },
   "outputs": [],
   "source": [
    "# Oversampling to fit majority class (none)\n",
    "ros = RandomOverSampler()\n",
    "X_train_os, y_train_os = ros.fit_resample(np.array(X_train).reshape(-1,1),np.array(y_train).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca3fcb1",
   "metadata": {
    "id": "6ca3fcb1"
   },
   "source": [
    "### BERT-specific Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2c1315e",
   "metadata": {
    "id": "f2c1315e"
   },
   "outputs": [],
   "source": [
    "X_train_os = X_train_os.flatten()\n",
    "y_train_os = y_train_os.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51b2f5fb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51b2f5fb",
    "outputId": "5d6d0a9c-e421-4d33-a186-6425bb51b729"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 5675],\n",
       "       [   1, 5675],\n",
       "       [   2, 5675]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_train_os, return_counts=True)\n",
    "np.asarray((unique, counts)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2ee356",
   "metadata": {
    "id": "5b2ee356"
   },
   "source": [
    "Since we need to tokenize the tweets (get \"input ids\" and \"attention masks\") for BERT, we load the specific BERT tokenizer from the Hugging Face library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8778c223",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "cd07d0ff7860450da87c5083c0dd7615",
      "7ecc6767399a4883b570fe109f08871b",
      "4121cec5ac524279b0ba785aaa582633",
      "44a5fb035b024e4ea749fcb4aed9d2ea",
      "ffa724cc3aaa4b989f324dd0872caff4",
      "9cbde03acb594d0d99adf823feda83ed",
      "37b6a386c9ba4358b53dfb20f71420d4",
      "ea019add2a52435990eaeb5a9d0752b1",
      "c9b24bb2a99d4ef887fd7430958843c5",
      "711c0738f99a4561bebb9b8d68e42e95",
      "74056b1550c2475f971d258521b4614b",
      "e6e0b500a25b47c1ad4ec24281cb745a",
      "9743e4dbf06f486aacb8875ca60552b0",
      "2421ee9dedfe4784a4e2266a9521d120",
      "248c9995ffc846b5a810151b43d281c0",
      "91db0e0c1f004117b3e87f1fac2342d2",
      "039301a5e5dc4a98908ba447615efdc8",
      "617c19411e99412e83da18305b39fe1f",
      "7a3670bfe46645389acf595e4f793ff2",
      "1702002d3dc649b39ec61a131aa7ed40",
      "c7efb20deb144db39de6db1d810faa0f",
      "6a1b7d6be87e4d7790288c386b689d47",
      "cede5da2c48c49e9a7d9c8a88e94e685",
      "5b1277cc77cf4459928b738eed971286",
      "9d3e1d1965d949e58ee47b239bfe1aec",
      "f383959b144c499e9673cd55e544fcef",
      "e9e4cf686bcb4c189110d7d72fb8eca7",
      "e39750067c4f432398a797268d435da7",
      "d994d243182a4c60a2ca9edf84356346",
      "fc81a808157e461b9a8b428b453436ac",
      "2d7a4473739e4623b695cf56dd476571",
      "c8710c013813454f9b462d205d1a3e88",
      "474da29f75274c7d827dac271a96ea39"
     ]
    },
    "id": "8778c223",
    "outputId": "df4ec393-c3e7-4f52-fa56-11fc91380b46"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd07d0ff7860450da87c5083c0dd7615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e0b500a25b47c1ad4ec24281cb745a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cede5da2c48c49e9a7d9c8a88e94e685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de81589b",
   "metadata": {
    "id": "de81589b"
   },
   "outputs": [],
   "source": [
    "# Defining a custom tokenizer function using the loaded tokenizer.\n",
    "def bert_tokenizer(data):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    for sent in data:\n",
    "        encoded_sent = tokenizer.encode_plus(\n",
    "            text=sent,\n",
    "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]` special tokens\n",
    "            max_length=MAX_LEN,             # Choose max length to truncate/pad\n",
    "            pad_to_max_length=True,         # Pad sentence to max length \n",
    "            return_attention_mask=True      # Return attention mask\n",
    "            )\n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc578cdf",
   "metadata": {
    "id": "bc578cdf"
   },
   "source": [
    "Since we need to specify the length of the longest tokenized sentence, we tokenize the train tweets using the \"encode\" method of the original BERT tokenizer and check the longest sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac9bf8f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ac9bf8f5",
    "outputId": "385e5507-22e2-4f02-ec5a-af19cf94ee7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length:  232\n"
     ]
    }
   ],
   "source": [
    "# Tokenize train tweets\n",
    "encoded_tweets = [tokenizer.encode(sent, add_special_tokens=True) for sent in X_train]\n",
    "\n",
    "# Find the longest tokenized tweet\n",
    "max_len = max([len(sent) for sent in encoded_tweets])\n",
    "print('Max length: ', max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9300996d",
   "metadata": {
    "id": "9300996d"
   },
   "source": [
    "Choosing the max length as slightly more than the max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e166389f",
   "metadata": {
    "id": "e166389f"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = max_len + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44731b3f",
   "metadata": {
    "id": "44731b3f"
   },
   "source": [
    "Then we can tokenize the train, validation and test tweets using the custom define tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31c78f31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31c78f31",
    "outputId": "fb21ac56-34d0-495e-ba4d-9fbec641c449"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2329: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "train_inputs, train_masks = bert_tokenizer(X_train_os)\n",
    "val_inputs, val_masks = bert_tokenizer(X_valid)\n",
    "test_inputs, test_masks = bert_tokenizer(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2a25a1",
   "metadata": {
    "id": "de2a25a1"
   },
   "source": [
    "### Data preprocessing for PyTorch BERT model\n",
    "\n",
    "Since we are using the BERT model built on PyTorch, we need to convert the arrays to pytorch tensors and create dataloaders for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "def39900",
   "metadata": {
    "id": "def39900"
   },
   "outputs": [],
   "source": [
    "# Convert target columns to pytorch tensors format\n",
    "train_labels = torch.from_numpy(y_train_os)\n",
    "val_labels = torch.from_numpy(y_valid)\n",
    "test_labels = torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2d0b0f",
   "metadata": {
    "id": "1d2d0b0f"
   },
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73983768",
   "metadata": {
    "id": "73983768"
   },
   "source": [
    "According to the author of this code (from Kaggle), it is mentioned that the original author of the BERT Model suggests a batch_size of 16 or 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "636b3e3d",
   "metadata": {
    "id": "636b3e3d"
   },
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d95fa603",
   "metadata": {
    "id": "d95fa603"
   },
   "outputs": [],
   "source": [
    "# Create the DataLoader for our training set\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our test set\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86df252a",
   "metadata": {
    "id": "86df252a"
   },
   "source": [
    "# BERT Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c81bfc",
   "metadata": {
    "id": "e9c81bfc"
   },
   "source": [
    "Now we can create a custom BERT classifier class, including the original BERT model (made of transformer layers) and additional Dense layers to perform the desired classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c6dae37",
   "metadata": {
    "id": "2c6dae37"
   },
   "outputs": [],
   "source": [
    "class Bert_Classifier(nn.Module):\n",
    "    def __init__(self, freeze_bert=False):\n",
    "        super(Bert_Classifier, self).__init__()\n",
    "        # Specify hidden size of BERT, hidden size of the classifier, and number of labels\n",
    "        n_input = 768\n",
    "        n_hidden = 50\n",
    "        # 3 n_output because there are 3 categories of tweets ('none': 0, 'racism': 1, 'sexism': 2)\n",
    "        n_output = 3\n",
    "        # Instantiate BERT model\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        # Add dense layers to perform the classification\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(n_input,  n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_output)\n",
    "        )\n",
    "        # Add possibility to freeze the BERT model\n",
    "        # to avoid fine tuning BERT params (usually leads to worse results)\n",
    "        if freeze_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Feed input data to BERT\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask)\n",
    "        \n",
    "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
    "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
    "\n",
    "        # Feed input to classifier to compute logits\n",
    "        logits = self.classifier(last_hidden_state_cls)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb597a85",
   "metadata": {
    "id": "fb597a85"
   },
   "source": [
    "Moreover, since we want to define a learning rate scheduler, we define a custom \"initalize_model\" function as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6149392",
   "metadata": {
    "id": "f6149392"
   },
   "outputs": [],
   "source": [
    "def initialize_model(epochs=4):\n",
    "    # Instantiate Bert Classifier\n",
    "    bert_classifier = Bert_Classifier(freeze_bert=False)\n",
    "    \n",
    "    bert_classifier.to(device)\n",
    "\n",
    "    # Set up optimizer\n",
    "    optimizer = AdamW(bert_classifier.parameters(),\n",
    "                      lr=5e-5,    # learning rate, set to default value\n",
    "                      eps=1e-8    # decay, set to default value\n",
    "                      )\n",
    "    \n",
    "    ### Set up learning rate scheduler ###\n",
    "\n",
    "    # Calculate total number of training steps\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    # Defint the scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=0, # Default value\n",
    "                                                num_training_steps=total_steps)\n",
    "    return bert_classifier, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b7c067",
   "metadata": {
    "id": "c6b7c067"
   },
   "source": [
    "We also specify the use of GPU if present (highly recommended for the fine tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80122e4e",
   "metadata": {
    "id": "80122e4e"
   },
   "outputs": [],
   "source": [
    "# Setting to run using cuda if present, else cpu\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "CH7K1Zd8vU9u",
   "metadata": {
    "id": "CH7K1Zd8vU9u"
   },
   "outputs": [],
   "source": [
    "# Setting number of epochs (# of times weights are updated, or # of iterations over the dataset)\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5927a47e",
   "metadata": {
    "id": "5927a47e"
   },
   "source": [
    "And then we intialize the BERT model calling the \"initialize_model\" function we defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b69e355f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156,
     "referenced_widgets": [
      "dcbc518f05a34d15a48fb738ccf53bf8",
      "c43039f7f72a48b5a38343c0f4cfaee1",
      "e08bbf20f2b749799f33efd79cac441c",
      "e9ce5dda3988400a90bd2972a0060a99",
      "d9a399731e974fffbd6074c2db1242b3",
      "a8958a93ea0c4929921539f29fec20e1",
      "2a3e24c4d9434e4ebc2c7c00b1d1e979",
      "128f724f0e2249ecafbf3cad3552b5d8",
      "6a0a333961694a579ec04f239354a89a",
      "d60678cee2644e9fa5b4b0f5afa5326c",
      "0337e20badba4f6da367ac584a829c72"
     ]
    },
    "id": "b69e355f",
    "outputId": "2926ffb7-5020-4df5-da35-20481ef66515"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcbc518f05a34d15a48fb738ccf53bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/420M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "bert_classifier, optimizer, scheduler = initialize_model(epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497e9f8a",
   "metadata": {
    "id": "497e9f8a"
   },
   "source": [
    "# BERT Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427f8e1a",
   "metadata": {
    "id": "427f8e1a"
   },
   "source": [
    "After defining the custom BERT classifier model, we are ready to start the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d382a9b",
   "metadata": {
    "id": "5d382a9b"
   },
   "outputs": [],
   "source": [
    "# Define Cross entropy Loss function for the multiclass classification task\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def bert_train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
    "\n",
    "    print(\"Start training...\\n\")\n",
    "    for epoch_i in range(epochs):\n",
    "        print(\"-\"*10)\n",
    "        print(\"Epoch : {}\".format(epoch_i+1))\n",
    "        print(\"-\"*10)\n",
    "        print(\"-\"*38)\n",
    "        print(f\"{'BATCH NO.':^7} | {'TRAIN LOSS':^12} | {'ELAPSED (s)':^9}\")\n",
    "        print(\"-\"*38)\n",
    "\n",
    "        # Measure the elapsed time of each epoch\n",
    "        t0_epoch, t0_batch = time.time(), time.time()\n",
    "\n",
    "        # Reset tracking variables at the beginning of each epoch\n",
    "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
    "        \n",
    "        ###TRAINING###\n",
    "\n",
    "        # Put the model into the training mode\n",
    "        model.train()\n",
    "\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            batch_counts +=1\n",
    "            \n",
    "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            # Zero out any previously calculated gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Perform a forward pass and get logits.\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "            # Compute loss and accumulate the loss values\n",
    "            loss = loss_fn(logits, b_labels)\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Perform a backward pass to calculate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # Update model parameters:\n",
    "            # fine tune BERT params and train additional dense layers\n",
    "            optimizer.step()\n",
    "            # update learning rate\n",
    "            scheduler.step()\n",
    "\n",
    "            # Print the loss values and time elapsed for every 100 batches\n",
    "            if (step % 100 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
    "                # Calculate time elapsed for 20 batches\n",
    "                time_elapsed = time.time() - t0_batch\n",
    "                \n",
    "                print(f\"{step:^9} | {batch_loss / batch_counts:^12.6f} | {time_elapsed:^9.2f}\")\n",
    "\n",
    "                # Reset batch tracking variables\n",
    "                batch_loss, batch_counts = 0, 0\n",
    "                t0_batch = time.time()\n",
    "\n",
    "        # Calculate the average loss over the entire training data\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        ###EVALUATION###\n",
    "        \n",
    "        # Put the model into the evaluation mode\n",
    "        model.eval()\n",
    "        \n",
    "        # Define empty lists to host accuracy and validation for each batch\n",
    "        val_accuracy = []\n",
    "        val_loss = []\n",
    "\n",
    "        for batch in val_dataloader:\n",
    "            batch_input_ids, batch_attention_mask, batch_labels = tuple(t.to(device) for t in batch)\n",
    "            \n",
    "            # We do not want to update the params during the evaluation,\n",
    "            # So we specify that we dont want to compute the gradients of the tensors\n",
    "            # by calling the torch.no_grad() method\n",
    "            with torch.no_grad():\n",
    "                logits = model(batch_input_ids, batch_attention_mask)\n",
    "\n",
    "            loss = loss_fn(logits, batch_labels)\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "            # Get the predictions starting from the logits (get index of highest logit)\n",
    "            preds = torch.argmax(logits, dim=1).flatten()\n",
    "\n",
    "            # Calculate the validation accuracy \n",
    "            accuracy = (preds == batch_labels).cpu().numpy().mean() * 100\n",
    "            val_accuracy.append(accuracy)\n",
    "\n",
    "        # Compute the average accuracy and loss over the validation set\n",
    "        val_loss = np.mean(val_loss)\n",
    "        val_accuracy = np.mean(val_accuracy)\n",
    "        \n",
    "        # Print performance over the entire training data\n",
    "        time_elapsed = time.time() - t0_epoch\n",
    "        print(\"-\"*61)\n",
    "        print(f\"{'AVG TRAIN LOSS':^12} | {'VAL LOSS':^10} | {'VAL ACCURACY (%)':^9} | {'ELAPSED (s)':^9}\")\n",
    "        print(\"-\"*61)\n",
    "        print(f\"{avg_train_loss:^14.6f} | {val_loss:^10.6f} | {val_accuracy:^17.2f} | {time_elapsed:^9.2f}\")\n",
    "        print(\"-\"*61)\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "57e9c69c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "57e9c69c",
    "outputId": "739459e6-c469-4e68-faf6-90785dfaddb4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      "----------\n",
      "Epoch : 1\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.440459   |   72.12  \n",
      "   200    |   0.257430   |   68.70  \n",
      "   300    |   0.213333   |   68.62  \n",
      "   400    |   0.192045   |   68.67  \n",
      "   500    |   0.177551   |   68.65  \n",
      "   532    |   0.189090   |   21.34  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.252482    |  0.240984  |       92.32       |  376.42  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 2\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.107854   |   69.29  \n",
      "   200    |   0.084654   |   68.64  \n",
      "   300    |   0.106094   |   68.63  \n",
      "   400    |   0.091647   |   68.65  \n",
      "   500    |   0.069460   |   68.66  \n",
      "   532    |   0.050806   |   21.34  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.089502    |  0.319845  |       91.64       |  373.53  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 3\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.030362   |   69.39  \n",
      "   200    |   0.044303   |   68.67  \n",
      "   300    |   0.047513   |   68.69  \n",
      "   400    |   0.054562   |   68.68  \n",
      "   500    |   0.058552   |   68.70  \n",
      "   532    |   0.069009   |   21.35  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.048345    |  0.338753  |       93.23       |  373.80  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 4\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.014797   |   69.34  \n",
      "   200    |   0.022858   |   68.69  \n",
      "   300    |   0.028017   |   68.67  \n",
      "   400    |   0.022934   |   68.62  \n",
      "   500    |   0.032266   |   68.67  \n",
      "   532    |   0.030639   |   21.35  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.024545    |  0.397733  |       93.31       |  373.65  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 5\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.014181   |   69.34  \n",
      "   200    |   0.017716   |   68.63  \n",
      "   300    |   0.020077   |   68.65  \n",
      "   400    |   0.018256   |   68.66  \n",
      "   500    |   0.025685   |   68.72  \n",
      "   532    |   0.042154   |   21.36  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.020553    |  0.428308  |       92.98       |  373.68  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 6\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.006684   |   69.41  \n",
      "   200    |   0.012202   |   68.71  \n",
      "   300    |   0.011471   |   68.70  \n",
      "   400    |   0.015568   |   68.65  \n",
      "   500    |   0.016485   |   68.63  \n",
      "   532    |   0.019603   |   21.34  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.012899    |  0.468596  |       92.82       |  373.75  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 7\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.003955   |   69.37  \n",
      "   200    |   0.008915   |   68.68  \n",
      "   300    |   0.018698   |   68.68  \n",
      "   400    |   0.004946   |   68.71  \n",
      "   500    |   0.013045   |   68.66  \n",
      "   532    |   0.004600   |   21.36  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.009582    |  0.567136  |       92.82       |  373.78  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 8\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.011273   |   69.36  \n",
      "   200    |   0.009063   |   68.71  \n",
      "   300    |   0.014555   |   68.66  \n",
      "   400    |   0.009047   |   68.64  \n",
      "   500    |   0.018169   |   68.67  \n",
      "   532    |   0.008433   |   21.33  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.012180    |  0.533233  |       92.65       |  373.66  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 9\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.007828   |   69.33  \n",
      "   200    |   0.013116   |   68.67  \n",
      "   300    |   0.017522   |   68.64  \n",
      "   400    |   0.007561   |   68.67  \n",
      "   500    |   0.013286   |   68.64  \n",
      "   532    |   0.017972   |   21.34  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.012222    |  0.609253  |       92.65       |  373.60  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 10\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.017306   |   69.33  \n",
      "   200    |   0.008490   |   68.70  \n",
      "   300    |   0.021701   |   68.64  \n",
      "   400    |   0.013315   |   68.66  \n",
      "   500    |   0.029280   |   68.67  \n",
      "   532    |   0.015387   |   21.34  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.017859    |  0.542323  |       92.57       |  373.65  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 11\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.009778   |   69.35  \n",
      "   200    |   0.021471   |   68.66  \n",
      "   300    |   0.006991   |   68.67  \n",
      "   400    |   0.007251   |   68.69  \n",
      "   500    |   0.014196   |   68.69  \n",
      "   532    |   0.016924   |   21.33  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.012233    |  0.573628  |       91.67       |  373.69  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 12\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.014655   |   69.41  \n",
      "   200    |   0.010971   |   68.69  \n",
      "   300    |   0.008255   |   68.67  \n",
      "   400    |   0.010683   |   68.68  \n",
      "   500    |   0.006346   |   68.67  \n",
      "   532    |   0.008403   |   21.35  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.010084    |  0.586259  |       92.41       |  373.75  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 13\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.003281   |   69.35  \n",
      "   200    |   0.012003   |   68.66  \n",
      "   300    |   0.009689   |   68.71  \n",
      "   400    |   0.008100   |   68.64  \n",
      "   500    |   0.008715   |   68.68  \n",
      "   532    |   0.003910   |   21.33  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.008081    |  0.563019  |       92.98       |  373.67  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 14\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.007077   |   69.40  \n",
      "   200    |   0.005110   |   68.69  \n",
      "   300    |   0.005675   |   68.70  \n",
      "   400    |   0.008346   |   68.74  \n",
      "   500    |   0.001480   |   68.73  \n",
      "   532    |   0.017525   |   21.35  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.006260    |  0.603586  |       92.65       |  373.92  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 15\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.001907   |   69.44  \n",
      "   200    |   0.006440   |   68.73  \n",
      "   300    |   0.014735   |   68.77  \n",
      "   400    |   0.008688   |   68.76  \n",
      "   500    |   0.004001   |   68.76  \n",
      "   532    |   0.005055   |   21.35  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.007018    |  0.692645  |       92.16       |  374.11  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 16\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.003150   |   69.44  \n",
      "   200    |   0.003485   |   68.79  \n",
      "   300    |   0.013184   |   68.76  \n",
      "   400    |   0.007371   |   68.78  \n",
      "   500    |   0.016301   |   68.78  \n",
      "   532    |   0.002312   |   21.36  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.008304    |  0.628662  |       92.74       |  374.23  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 17\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.002299   |   69.47  \n",
      "   200    |   0.008396   |   68.81  \n",
      "   300    |   0.001393   |   68.79  \n",
      "   400    |   0.001512   |   68.78  \n",
      "   500    |   0.011550   |   68.83  \n",
      "   532    |   0.003244   |   21.37  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.004918    |  0.723932  |       92.49       |  374.35  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 18\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.012984   |   69.49  \n",
      "   200    |   0.005110   |   68.81  \n",
      "   300    |   0.005833   |   68.76  \n",
      "   400    |   0.005246   |   68.79  \n",
      "   500    |   0.004846   |   68.82  \n",
      "   532    |   0.002938   |   21.37  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.006583    |  0.724712  |       92.41       |  374.34  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 19\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.005763   |   69.47  \n",
      "   200    |   0.010492   |   68.84  \n",
      "   300    |   0.005827   |   68.79  \n",
      "   400    |   0.001598   |   68.80  \n",
      "   500    |   0.008217   |   68.81  \n",
      "   532    |   0.007143   |   21.38  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.006424    |  0.693918  |       92.65       |  374.40  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 20\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.013084   |   69.46  \n",
      "   200    |   0.005533   |   68.80  \n",
      "   300    |   0.015093   |   68.76  \n",
      "   400    |   0.021398   |   68.82  \n",
      "   500    |   0.016906   |   68.76  \n",
      "   532    |   0.009671   |   21.37  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.014116    |  0.606084  |       92.32       |  374.27  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 21\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.015369   |   69.50  \n",
      "   200    |   0.010153   |   68.75  \n",
      "   300    |   0.006898   |   68.80  \n",
      "   400    |   0.006330   |   68.80  \n",
      "   500    |   0.006691   |   68.75  \n",
      "   532    |   0.012006   |   21.39  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.009275    |  0.625836  |       92.65       |  374.28  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 22\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.006157   |   69.45  \n",
      "   200    |   0.006106   |   68.79  \n",
      "   300    |   0.004394   |   68.79  \n",
      "   400    |   0.004519   |   68.82  \n",
      "   500    |   0.004403   |   68.81  \n",
      "   532    |   0.002126   |   21.38  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.004938    |  0.729603  |       92.24       |  374.35  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 23\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.004688   |   69.47  \n",
      "   200    |   0.003965   |   68.78  \n",
      "   300    |   0.001432   |   68.76  \n",
      "   400    |   0.006170   |   68.75  \n",
      "   500    |   0.005862   |   68.80  \n",
      "   532    |   0.002600   |   21.38  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.004314    |  0.646878  |       92.74       |  374.25  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 24\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.000399   |   69.49  \n",
      "   200    |   0.000958   |   68.78  \n",
      "   300    |   0.001721   |   68.77  \n",
      "   400    |   0.000727   |   68.77  \n",
      "   500    |   0.003448   |   68.79  \n",
      "   532    |   0.001230   |   21.38  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.001436    |  0.703437  |       92.57       |  374.28  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 25\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.001065   |   69.54  \n",
      "   200    |   0.000912   |   68.77  \n",
      "   300    |   0.001160   |   68.78  \n",
      "   400    |   0.001935   |   68.77  \n",
      "   500    |   0.003006   |   68.77  \n",
      "   532    |   0.001834   |   21.35  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.001628    |  0.761698  |       92.32       |  374.28  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 26\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.001952   |   69.47  \n",
      "   200    |   0.006085   |   68.79  \n",
      "   300    |   0.007416   |   68.74  \n",
      "   400    |   0.005663   |   68.73  \n",
      "   500    |   0.003477   |   68.75  \n",
      "   532    |   0.000586   |   21.38  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.004653    |  0.772434  |       92.57       |  374.16  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 27\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.010156   |   69.42  \n",
      "   200    |   0.003689   |   68.75  \n",
      "   300    |   0.000552   |   68.69  \n",
      "   400    |   0.001883   |   68.70  \n",
      "   500    |   0.010933   |   68.77  \n",
      "   532    |   0.003034   |   21.35  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.005307    |  0.740929  |       91.91       |  373.97  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 28\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.011133   |   69.44  \n",
      "   200    |   0.004254   |   68.72  \n",
      "   300    |   0.002357   |   68.71  \n",
      "   400    |   0.001096   |   68.66  \n",
      "   500    |   0.001909   |   68.66  \n",
      "   532    |   0.000598   |   21.36  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.003950    |  0.740660  |       92.65       |  373.84  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 29\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.007887   |   69.38  \n",
      "   200    |   0.001681   |   68.68  \n",
      "   300    |   0.001264   |   68.69  \n",
      "   400    |   0.000670   |   68.68  \n",
      "   500    |   0.001953   |   68.67  \n",
      "   532    |   0.005316   |   21.35  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.002858    |  0.737105  |       93.06       |  373.74  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 30\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.010934   |   69.33  \n",
      "   200    |   0.006599   |   68.64  \n",
      "   300    |   0.000978   |   68.62  \n",
      "   400    |   0.000391   |   68.67  \n",
      "   500    |   0.003468   |   68.64  \n",
      "   532    |   0.001858   |   21.33  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.004329    |  0.762719  |       92.41       |  373.53  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 31\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.001179   |   69.32  \n",
      "   200    |   0.000724   |   68.65  \n",
      "   300    |   0.001032   |   68.69  \n",
      "   400    |   0.002612   |   68.64  \n",
      "   500    |   0.007455   |   68.64  \n",
      "   532    |   0.000025   |   21.34  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.002443    |  0.733726  |       92.90       |  373.56  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 32\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.001145   |   69.33  \n",
      "   200    |   0.001268   |   68.63  \n",
      "   300    |   0.000903   |   68.68  \n",
      "   400    |   0.001016   |   68.71  \n",
      "   500    |   0.001267   |   68.67  \n",
      "   532    |   0.002906   |   21.31  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.001227    |  0.792321  |       92.82       |  373.62  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 33\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.000775   |   69.32  \n",
      "   200    |   0.001104   |   68.60  \n",
      "   300    |   0.001883   |   68.66  \n",
      "   400    |   0.007149   |   68.63  \n",
      "   500    |   0.006489   |   68.62  \n",
      "   532    |   0.002773   |   21.34  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.003433    |  0.733109  |       92.90       |  373.47  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 34\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.001143   |   69.31  \n",
      "   200    |   0.001998   |   68.57  \n",
      "   300    |   0.003838   |   68.61  \n",
      "   400    |   0.005873   |   68.64  \n",
      "   500    |   0.005286   |   68.60  \n",
      "   532    |   0.011585   |   21.31  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.004101    |  0.743493  |       92.41       |  373.35  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 35\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.011550   |   69.31  \n",
      "   200    |   0.007465   |   68.59  \n",
      "   300    |   0.001214   |   68.60  \n",
      "   400    |   0.002903   |   68.59  \n",
      "   500    |   0.001509   |   68.59  \n",
      "   532    |   0.000055   |   21.31  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.004648    |  0.751713  |       92.57       |  373.28  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 36\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.000877   |   69.28  \n",
      "   200    |   0.004459   |   68.58  \n",
      "   300    |   0.003377   |   68.58  \n",
      "   400    |   0.001793   |   68.75  \n",
      "   500    |   0.000683   |   68.57  \n",
      "   532    |   0.009262   |   21.29  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.002657    |  0.717248  |       92.32       |  373.35  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 37\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.000925   |   69.26  \n",
      "   200    |   0.001127   |   68.59  \n",
      "   300    |   0.001145   |   68.60  \n",
      "   400    |   0.001314   |   68.56  \n",
      "   500    |   0.005843   |   68.59  \n",
      "   532    |   0.009204   |   21.31  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.002497    |  0.696468  |       92.74       |  373.23  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 38\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.003426   |   69.28  \n",
      "   200    |   0.001016   |   68.58  \n",
      "   300    |   0.001482   |   68.55  \n",
      "   400    |   0.001554   |   68.62  \n",
      "   500    |   0.000299   |   68.60  \n",
      "   532    |   0.001417   |   21.31  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.001550    |  0.784515  |       92.65       |  373.24  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 39\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.004358   |   69.26  \n",
      "   200    |   0.000727   |   68.58  \n",
      "   300    |   0.001395   |   68.54  \n",
      "   400    |   0.000445   |   68.55  \n",
      "   500    |   0.002043   |   68.55  \n",
      "   532    |   0.001751   |   21.32  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.001796    |  0.782687  |       92.74       |  373.08  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 40\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.001184   |   69.25  \n",
      "   200    |   0.000643   |   68.57  \n",
      "   300    |   0.001004   |   68.57  \n",
      "   400    |   0.000766   |   68.53  \n",
      "   500    |   0.002195   |   68.59  \n",
      "   532    |   0.003051   |   21.32  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.001272    |  0.801404  |       92.74       |  373.13  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 41\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.000348   |   69.27  \n",
      "   200    |   0.002070   |   68.59  \n",
      "   300    |   0.001241   |   68.59  \n",
      "   400    |   0.001178   |   68.56  \n",
      "   500    |   0.001964   |   68.58  \n",
      "   532    |   0.000915   |   21.34  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.001332    |  0.824949  |       92.82       |  373.22  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 42\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.002827   |   69.29  \n",
      "   200    |   0.001026   |   68.62  \n",
      "   300    |   0.001311   |   68.63  \n",
      "   400    |   0.001097   |   68.67  \n",
      "   500    |   0.003640   |   68.60  \n",
      "   532    |   0.001976   |   21.34  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.001982    |  0.850513  |       92.57       |  373.45  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 43\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.000739   |   69.27  \n",
      "   200    |   0.001022   |   68.64  \n",
      "   300    |   0.000899   |   68.63  \n",
      "   400    |   0.001863   |   68.62  \n",
      "   500    |   0.001121   |   68.71  \n",
      "   532    |   0.001778   |   21.35  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.001167    |  0.859186  |       92.57       |  373.53  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 44\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.000508   |   69.38  \n",
      "   200    |   0.002444   |   68.72  \n",
      "   300    |   0.000715   |   68.69  \n",
      "   400    |   0.001013   |   68.71  \n",
      "   500    |   0.000972   |   68.71  \n",
      "   532    |   0.001654   |   21.36  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.001160    |  0.865726  |       92.65       |  373.87  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 45\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.000280   |   69.42  \n",
      "   200    |   0.000750   |   68.74  \n",
      "   300    |   0.002035   |   68.71  \n",
      "   400    |   0.000819   |   68.70  \n",
      "   500    |   0.004725   |   68.74  \n",
      "   532    |   0.001131   |   21.35  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.001684    |  0.852286  |       92.49       |  373.97  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 46\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.001494   |   69.37  \n",
      "   200    |   0.001182   |   68.68  \n",
      "   300    |   0.001510   |   68.71  \n",
      "   400    |   0.000635   |   68.68  \n",
      "   500    |   0.000899   |   68.69  \n",
      "   532    |   0.001454   |   21.35  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.001163    |  0.862971  |       92.49       |  373.78  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 47\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.000669   |   69.41  \n",
      "   200    |   0.002330   |   68.73  \n",
      "   300    |   0.001041   |   68.72  \n",
      "   400    |   0.005168   |   68.71  \n",
      "   500    |   0.000560   |   68.73  \n",
      "   532    |   0.000537   |   21.36  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.001866    |  0.849808  |       92.49       |  373.96  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 48\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.001624   |   69.40  \n",
      "   200    |   0.000540   |   68.70  \n",
      "   300    |   0.002601   |   68.70  \n",
      "   400    |   0.000092   |   68.72  \n",
      "   500    |   0.001115   |   68.69  \n",
      "   532    |   0.000269   |   21.36  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.001139    |  0.855519  |       92.49       |  373.87  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 49\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.001719   |   69.41  \n",
      "   200    |   0.001211   |   68.69  \n",
      "   300    |   0.000657   |   68.83  \n",
      "   400    |   0.001168   |   68.71  \n",
      "   500    |   0.000466   |   68.75  \n",
      "   532    |   0.002603   |   21.38  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.001139    |  0.859019  |       92.49       |  374.07  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------\n",
      "Epoch : 50\n",
      "----------\n",
      "--------------------------------------\n",
      "BATCH NO. |  TRAIN LOSS  | ELAPSED (s)\n",
      "--------------------------------------\n",
      "   100    |   0.001513   |   69.44  \n",
      "   200    |   0.001127   |   68.73  \n",
      "   300    |   0.001517   |   68.72  \n",
      "   400    |   0.000672   |   68.71  \n",
      "   500    |   0.000948   |   68.77  \n",
      "   532    |   0.001007   |   21.36  \n",
      "-------------------------------------------------------------\n",
      "AVG TRAIN LOSS |  VAL LOSS  | VAL ACCURACY (%) | ELAPSED (s)\n",
      "-------------------------------------------------------------\n",
      "   0.001147    |  0.860187  |       92.41       |  374.04  \n",
      "-------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Training BERT model\n",
    "bert_train(bert_classifier, train_dataloader, val_dataloader, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ddaf22",
   "metadata": {
    "id": "c4ddaf22"
   },
   "source": [
    "# BERT Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b874cb06",
   "metadata": {
    "id": "b874cb06"
   },
   "source": [
    "Now we define a function similar to the model \"evaluation\", where we feed to the model the test data instead of the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ff45c15a",
   "metadata": {
    "id": "ff45c15a"
   },
   "outputs": [],
   "source": [
    "def bert_predict(model, test_dataloader):\n",
    "    \n",
    "    # Define empty list to host the predictions\n",
    "    preds_list = []\n",
    "    \n",
    "    # Put the model into evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    for batch in test_dataloader:\n",
    "        batch_input_ids, batch_attention_mask = tuple(t.to(device) for t in batch)[:2]\n",
    "        \n",
    "        # Avoid gradient calculation of tensors by using \"no_grad()\" method\n",
    "        with torch.no_grad():\n",
    "            logit = model(batch_input_ids, batch_attention_mask)\n",
    "        \n",
    "        # Get index of highest logit\n",
    "        pred = torch.argmax(logit,dim=1).cpu().numpy()\n",
    "        # Append predicted class to list\n",
    "        preds_list.extend(pred)\n",
    "\n",
    "    return preds_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222acdb4",
   "metadata": {
    "id": "222acdb4"
   },
   "source": [
    "Then we can call the defined function and get the class predictions of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "25705e6b",
   "metadata": {
    "id": "25705e6b"
   },
   "outputs": [],
   "source": [
    "bert_preds = bert_predict(bert_classifier, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133ae7ee",
   "metadata": {
    "id": "133ae7ee"
   },
   "source": [
    "# Results from BERT Classifer Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13f0c5a",
   "metadata": {
    "id": "d13f0c5a"
   },
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1baa3f31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1baa3f31",
    "outputId": "d0c22351-1aa2-46e2-b36e-bb457accbaf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for BERT (50 Epochs) :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        none       0.85      0.83      0.84       644\n",
      "      racism       0.96      0.98      0.97      1576\n",
      "      sexism       0.92      0.90      0.91       755\n",
      "\n",
      "    accuracy                           0.93      2975\n",
      "   macro avg       0.91      0.91      0.91      2975\n",
      "weighted avg       0.93      0.93      0.93      2975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report for BERT (50 Epochs) :\\n', classification_report(y_test, bert_preds, target_names= tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acbd7d5",
   "metadata": {
    "id": "9acbd7d5"
   },
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c3f7b49",
   "metadata": {
    "id": "3c3f7b49"
   },
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_true = y_test, y_pred = bert_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "73933392",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "73933392",
    "outputId": "dd5030f2-cf75-47a8-cb59-df44df949050"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues', fmt='g')\n",
    "\n",
    "ax.set_title('BERT Model (50 Epochs) Confusion Matrix\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['None','Racist','Sexist'])\n",
    "ax.yaxis.set_ticklabels(['None','Racist','Sexist'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3959b35",
   "metadata": {
    "id": "f3959b35"
   },
   "source": [
    "It can be observed that the model unsurprisingly best classifies a racist tweet correctly given most tweets are labelled racist in the train dataset.\n",
    "\n",
    "Generally, the BERT model is able to correctly label the tweets with the correct tagging, as seen from the f1 score of each label scoring well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5abb3c94",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5abb3c94",
    "outputId": "30c940b4-60e0-4449-a6f5-2cd2d06d29d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 14s, sys: 74 ms, total: 1min 14s\n",
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bert_preds = bert_predict(bert50_model, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d7c460f8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7c460f8",
    "outputId": "709f95f8-42ec-49c9-cb5c-c066d20a279d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999159628096131"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcuating F1-score on training set\n",
    "bert_f1 = f1_score(y_train, bert_preds, average = 'weighted')\n",
    "bert_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5d5c60",
   "metadata": {
    "id": "4e5d5c60"
   },
   "source": [
    "# Saving BERT Model with 50 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c21508d",
   "metadata": {
    "id": "2c21508d"
   },
   "outputs": [],
   "source": [
    "# Saving Model\n",
    "pickle.dump(bert_classifier, open('/content/drive/MyDrive/Capstone/data/bert50.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "5. Capstone - Modelling (BERT 50 Epochs) .ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0337e20badba4f6da367ac584a829c72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "039301a5e5dc4a98908ba447615efdc8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "128f724f0e2249ecafbf3cad3552b5d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1702002d3dc649b39ec61a131aa7ed40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2421ee9dedfe4784a4e2266a9521d120": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a3670bfe46645389acf595e4f793ff2",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1702002d3dc649b39ec61a131aa7ed40",
      "value": 28
     }
    },
    "248c9995ffc846b5a810151b43d281c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c7efb20deb144db39de6db1d810faa0f",
      "placeholder": "​",
      "style": "IPY_MODEL_6a1b7d6be87e4d7790288c386b689d47",
      "value": " 28.0/28.0 [00:00&lt;00:00, 1.00kB/s]"
     }
    },
    "2a3e24c4d9434e4ebc2c7c00b1d1e979": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2d7a4473739e4623b695cf56dd476571": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "37b6a386c9ba4358b53dfb20f71420d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4121cec5ac524279b0ba785aaa582633": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea019add2a52435990eaeb5a9d0752b1",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c9b24bb2a99d4ef887fd7430958843c5",
      "value": 231508
     }
    },
    "44a5fb035b024e4ea749fcb4aed9d2ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_711c0738f99a4561bebb9b8d68e42e95",
      "placeholder": "​",
      "style": "IPY_MODEL_74056b1550c2475f971d258521b4614b",
      "value": " 226k/226k [00:00&lt;00:00, 865kB/s]"
     }
    },
    "474da29f75274c7d827dac271a96ea39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b1277cc77cf4459928b738eed971286": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e39750067c4f432398a797268d435da7",
      "placeholder": "​",
      "style": "IPY_MODEL_d994d243182a4c60a2ca9edf84356346",
      "value": "Downloading config.json: 100%"
     }
    },
    "617c19411e99412e83da18305b39fe1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6a0a333961694a579ec04f239354a89a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6a1b7d6be87e4d7790288c386b689d47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "711c0738f99a4561bebb9b8d68e42e95": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74056b1550c2475f971d258521b4614b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7a3670bfe46645389acf595e4f793ff2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ecc6767399a4883b570fe109f08871b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9cbde03acb594d0d99adf823feda83ed",
      "placeholder": "​",
      "style": "IPY_MODEL_37b6a386c9ba4358b53dfb20f71420d4",
      "value": "Downloading vocab.txt: 100%"
     }
    },
    "91db0e0c1f004117b3e87f1fac2342d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9743e4dbf06f486aacb8875ca60552b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_039301a5e5dc4a98908ba447615efdc8",
      "placeholder": "​",
      "style": "IPY_MODEL_617c19411e99412e83da18305b39fe1f",
      "value": "Downloading tokenizer_config.json: 100%"
     }
    },
    "9cbde03acb594d0d99adf823feda83ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d3e1d1965d949e58ee47b239bfe1aec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc81a808157e461b9a8b428b453436ac",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2d7a4473739e4623b695cf56dd476571",
      "value": 570
     }
    },
    "a8958a93ea0c4929921539f29fec20e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c43039f7f72a48b5a38343c0f4cfaee1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a8958a93ea0c4929921539f29fec20e1",
      "placeholder": "​",
      "style": "IPY_MODEL_2a3e24c4d9434e4ebc2c7c00b1d1e979",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "c7efb20deb144db39de6db1d810faa0f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8710c013813454f9b462d205d1a3e88": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9b24bb2a99d4ef887fd7430958843c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cd07d0ff7860450da87c5083c0dd7615": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7ecc6767399a4883b570fe109f08871b",
       "IPY_MODEL_4121cec5ac524279b0ba785aaa582633",
       "IPY_MODEL_44a5fb035b024e4ea749fcb4aed9d2ea"
      ],
      "layout": "IPY_MODEL_ffa724cc3aaa4b989f324dd0872caff4"
     }
    },
    "cede5da2c48c49e9a7d9c8a88e94e685": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5b1277cc77cf4459928b738eed971286",
       "IPY_MODEL_9d3e1d1965d949e58ee47b239bfe1aec",
       "IPY_MODEL_f383959b144c499e9673cd55e544fcef"
      ],
      "layout": "IPY_MODEL_e9e4cf686bcb4c189110d7d72fb8eca7"
     }
    },
    "d60678cee2644e9fa5b4b0f5afa5326c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d994d243182a4c60a2ca9edf84356346": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d9a399731e974fffbd6074c2db1242b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dcbc518f05a34d15a48fb738ccf53bf8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c43039f7f72a48b5a38343c0f4cfaee1",
       "IPY_MODEL_e08bbf20f2b749799f33efd79cac441c",
       "IPY_MODEL_e9ce5dda3988400a90bd2972a0060a99"
      ],
      "layout": "IPY_MODEL_d9a399731e974fffbd6074c2db1242b3"
     }
    },
    "e08bbf20f2b749799f33efd79cac441c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_128f724f0e2249ecafbf3cad3552b5d8",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6a0a333961694a579ec04f239354a89a",
      "value": 440473133
     }
    },
    "e39750067c4f432398a797268d435da7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6e0b500a25b47c1ad4ec24281cb745a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9743e4dbf06f486aacb8875ca60552b0",
       "IPY_MODEL_2421ee9dedfe4784a4e2266a9521d120",
       "IPY_MODEL_248c9995ffc846b5a810151b43d281c0"
      ],
      "layout": "IPY_MODEL_91db0e0c1f004117b3e87f1fac2342d2"
     }
    },
    "e9ce5dda3988400a90bd2972a0060a99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d60678cee2644e9fa5b4b0f5afa5326c",
      "placeholder": "​",
      "style": "IPY_MODEL_0337e20badba4f6da367ac584a829c72",
      "value": " 420M/420M [00:27&lt;00:00, 18.7MB/s]"
     }
    },
    "e9e4cf686bcb4c189110d7d72fb8eca7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea019add2a52435990eaeb5a9d0752b1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f383959b144c499e9673cd55e544fcef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c8710c013813454f9b462d205d1a3e88",
      "placeholder": "​",
      "style": "IPY_MODEL_474da29f75274c7d827dac271a96ea39",
      "value": " 570/570 [00:00&lt;00:00, 19.3kB/s]"
     }
    },
    "fc81a808157e461b9a8b428b453436ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ffa724cc3aaa4b989f324dd0872caff4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
