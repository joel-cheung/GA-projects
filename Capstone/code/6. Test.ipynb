{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e1ffbc6",
   "metadata": {
    "id": "0e1ffbc6"
   },
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Capstone Project - Identifying Offensive Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f936554",
   "metadata": {
    "id": "5f936554"
   },
   "source": [
    "# Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9c0cb3",
   "metadata": {
    "id": "2d9c0cb3"
   },
   "source": [
    "This is my capstone project for the General Assembly Data Science Immersive course.\n",
    "\n",
    "This is the final notebook of this project.\n",
    "\n",
    "In this notebook, the steps conducted are:\n",
    "\n",
    "    1. Obtaining test score of the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c4812a",
   "metadata": {
    "id": "92c4812a"
   },
   "source": [
    "**CONTENT WARNING: This project includes content that are sensitive and may be offensive to some viewers. These topics include mentions (many negative) and slurs of race, religion, and gender.**\n",
    "\n",
    "**NOTE: All text information that are used in this project are directly taken from the websites and do not reflect what I believe in. All tags (whether a tweet is racist/sexist, or not) are taken as is from the source.**\n",
    "\n",
    "For the purpose of this project, the offensive tweets of interest are ones that are racist and sexist. \n",
    "\n",
    "Racist tweets are defined as those that have antagonistic sentiments toward certain religious figures or individuals from a religious group, and/or individuals or groups from a certain race. Given the dataset 'classified_tweets' not separating the racist and sacrilegious/blasphemous (anti-religious) tweets, the 'racist' tag will be applied for both categories.\n",
    "\n",
    "Sexist tweets are defined as those that have misogynistic, homophobic, and/or transphobic sentiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d65564",
   "metadata": {
    "id": "a5d65564"
   },
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157cf96c",
   "metadata": {
    "id": "157cf96c"
   },
   "source": [
    "Twitter is a micro-blogging social media platform with 217.5 million daily active users globally. With 500 million new tweets (posts) daily, the topics of these tweets varies widely – k-pop, politics, financial news… you name it! Individuals use it for news, entertainment, and discussions, while corporations use them to as a marketing tool to reach out to a wide audience. Given the freedom Twitter accords to its user, Twitter can provide a conducive environment for productive discourse, but this freedom can also be abused, manifesting in the forms of racism and sexism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f86b5f5",
   "metadata": {
    "id": "1f86b5f5"
   },
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42db16da",
   "metadata": {
    "id": "42db16da"
   },
   "source": [
    "With Twitter’s significant income stream coming from advertisers, it is imperative that Twitter keeps a substantial user base. On the other hand, Twitter should maintain a safe space for users and provide some level of checks for the tweets the users put out into the public space, and the first step would be to identify tweets that espouse racist or sexist ideologies, and then Twitter can direct the users to appropriate sources of information where users can learn more about the community that they offend or their subconscious biases so they will be more aware of their racist/sexist tendencies. Thus, to balance, Twitter has to be accurate in filtering inappropriate tweets from innocuous ones, and the kind of inappropriateness of flagged tweets (tag - racist or sexist).\n",
    "\n",
    "F1-scores will be the primary metric as it looks at both precision and recall, each looking at false positives (FPs) and false negatives (FNs) respectively, and is a popular metric for imbalanced data as is the case with the dataset used.\n",
    "\n",
    "For the purpose of explanation, racist tweets are used as the ‘positive’ case.\n",
    "\n",
    "In this context, FPs are the cases where the model erroneously flags out tweets as racist when the tweet is actually innocuous/sexist. FNs are cases where the model erroneously flags out tweets as innocuous/sexist but the tweets are actually racist.\n",
    "\n",
    "There is a need to balance the identification of an offensive tweet when it is indeed offensive and the need to maintain a high level of user experience (something that would be jeopardized when the model erroneously flags innocuous tweets as offensive).\n",
    "\n",
    "Thus, higher F1-score is the preferred metric to assess model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9026d2",
   "metadata": {
    "id": "9c9026d2"
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e9f669e",
   "metadata": {
    "id": "1e9f669e"
   },
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For NLP data cleaning and preprocessing\n",
    "import re, string, nltk, itertools\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Pickle to save model\n",
    "import pickle\n",
    "\n",
    "# For NLP Machine Learning processes\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "# Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Support Vector Machine\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# Transformers library for BERT\n",
    "import transformers\n",
    "from transformers import BertModel\n",
    "from transformers import BertTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, plot_roc_curve, RocCurveDisplay\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, plot_confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "736ea6af",
   "metadata": {
    "id": "736ea6af"
   },
   "outputs": [],
   "source": [
    "# Changing display settings\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.max_row', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0938a3eb",
   "metadata": {
    "id": "0938a3eb"
   },
   "source": [
    "# Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e1f04d8",
   "metadata": {
    "id": "4e1f04d8"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('D:/General Assembly/GA-projects/Capstone - Revisited/data/data_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "507b4823",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1660193145401,
     "user": {
      "displayName": "Joel",
      "userId": "13831783905850790679"
     },
     "user_tz": -480
    },
    "id": "507b4823",
    "outputId": "88a35d98-1993-4667-a7d1-8fa8150be63b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>set</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>way insult direct man unflattering hat worn predominantly men meant ins…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>ordinary muslim idiot person like know make sure qur’an muslim nothing claim jihad come back tal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>give buildup sweeden government idiotu behave like allrounder see reach god know many fake news ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>sure pot cooked hot mkr killerblondes abarmezh86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>christian part palestinian kill driven palestinian muslim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tag    set  \\\n",
       "0    2  train   \n",
       "1    1  train   \n",
       "2    1  train   \n",
       "3    0  train   \n",
       "4    1  train   \n",
       "\n",
       "                                                                                                  text  \n",
       "0                             way insult direct man unflattering hat worn predominantly men meant ins…  \n",
       "1  ordinary muslim idiot person like know make sure qur’an muslim nothing claim jihad come back tal...  \n",
       "2  give buildup sweeden government idiotu behave like allrounder see reach god know many fake news ...  \n",
       "3                                                     sure pot cooked hot mkr killerblondes abarmezh86  \n",
       "4                                            christian part palestinian kill driven palestinian muslim  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647b242a",
   "metadata": {},
   "source": [
    "# General Preprocessing of Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb113c46",
   "metadata": {
    "id": "bb113c46"
   },
   "outputs": [],
   "source": [
    "# Retrieving test set from entire dataset\n",
    "train = data.loc[data['set'] == 'train']\n",
    "test = data.loc[data['set'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8038927c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag       0\n",
       "set       0\n",
       "text    228\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking for missing values\n",
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14e79269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag     0\n",
       "set     0\n",
       "text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping rows with missing values\n",
    "test = test.dropna()\n",
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ca36b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting test dataset into X and y columns\n",
    "X = test['text']\n",
    "y = test['tag']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b906c4",
   "metadata": {},
   "source": [
    "# Loading Trained Models\n",
    "\n",
    "These models are:\n",
    "1. Multinomial Naive Bayes using CountVectorizer\n",
    "2. Random Forest using TfidfVectorizer\n",
    "3. Support Vector Machine using CountVectorizer\n",
    "4. BERT model\n",
    "\n",
    "They are used because they have a higher validation score compared to the other version using the other vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c2d534d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading cvec Multinomial NB model\n",
    "multi_nb_model = pickle.load(open(\"D:/General Assembly/GA-projects/Capstone - Revisited/data/cvec_multinomial.pkl\", \"rb\"))\n",
    "\n",
    "# Loading tvec Random Forest model\n",
    "rf_model = pickle.load(open(\"D:/General Assembly/GA-projects/Capstone - Revisited/data/tvec_rf.pkl\", \"rb\"))\n",
    "\n",
    "# loading cvec SVM model\n",
    "svm_model = pickle.load(open(\"D:/General Assembly/GA-projects/Capstone - Revisited/data/cvec_svm.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110725c3",
   "metadata": {
    "id": "110725c3"
   },
   "source": [
    "# Retrieving Test Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce97839",
   "metadata": {
    "id": "5ce97839"
   },
   "source": [
    "### Multinomial Naive Bayes (CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "287db410",
   "metadata": {
    "id": "287db410"
   },
   "outputs": [],
   "source": [
    "# Predicting tags on test set\n",
    "multi_nb_pred = multi_nb_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6bdcb0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9281, 5530, 2225],\n",
       "       [  64,  869,   12],\n",
       "       [ 579,  209,  937]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing confusion matrix\n",
    "confusion_matrix(y, multi_nb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "796c2460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6397351961194994"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcuating F1-score\n",
    "multi_nb_f1 = f1_score(y, multi_nb_pred, average = 'weighted')\n",
    "multi_nb_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbe5a91",
   "metadata": {},
   "source": [
    "### Random Forest (TF-IDF Vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c44152b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting tags on test set\n",
    "rf_pred = rf_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98f56159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15252,   681,  1103],\n",
       "       [  125,   800,    20],\n",
       "       [  533,    14,  1178]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing confusion matrix\n",
    "confusion_matrix(y, rf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b42d3d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8831018640291008"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcuating F1-score\n",
    "rf_f1 = f1_score(y, rf_pred, average = 'weighted')\n",
    "rf_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e476502",
   "metadata": {},
   "source": [
    "### Support Vector Machine (CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38d32676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting tags on test set\n",
    "svm_pred = svm_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "321cae15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15347,   607,  1082],\n",
       "       [  208,   722,    15],\n",
       "       [  550,    14,  1161]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing confusion matrix\n",
    "confusion_matrix(y, svm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7d4dcf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8819736691263095"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcuating F1-score\n",
    "svm_f1 = f1_score(y, svm_pred, average = 'weighted')\n",
    "svm_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58df54b1",
   "metadata": {},
   "source": [
    "### BERT\n",
    "\n",
    "Unlike the other models, there is a need to have a BERT-specific preprocessing of test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb6061c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1f62bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "155db8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length:  114\n"
     ]
    }
   ],
   "source": [
    "# Tokenize train tweets\n",
    "encoded_tweets = [tokenizer.encode(sent, add_special_tokens=True) for sent in X]\n",
    "\n",
    "# Find the longest tokenized tweet\n",
    "max_len = max([len(sent) for sent in encoded_tweets])\n",
    "print('Max length: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "57d0f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting max length to the longest text in test set\n",
    "MAX_LEN = max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4a66b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a custom tokenizer function using the loaded tokenizer.\n",
    "def bert_tokenizer(data):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    for sent in data:\n",
    "        encoded_sent = tokenizer.encode_plus(\n",
    "            text=sent,\n",
    "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]` special tokens\n",
    "            max_length=MAX_LEN,             # Choose max length to truncate/pad\n",
    "            pad_to_max_length=True,         # Pad sentence to max length \n",
    "            return_attention_mask=True      # Return attention mask\n",
    "            )\n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a0ab0a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_inputs, test_masks = bert_tokenizer(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eb134f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.to_numpy()\n",
    "\n",
    "test_labels = torch.from_numpy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4d0eddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataLoader for our test set\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size= 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "456232c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating BERT class\n",
    "class Bert_Classifier(nn.Module):\n",
    "    def __init__(self, freeze_bert=False):\n",
    "        super(Bert_Classifier, self).__init__()\n",
    "        # Specify hidden size of BERT, hidden size of the classifier, and number of labels\n",
    "        n_input = 768\n",
    "        n_hidden = 50\n",
    "        # 3 n_output because there are 3 categories of tweets ('none': 0, 'sexism': 1, 'racism': 2)\n",
    "        n_output = 3\n",
    "        # Instantiate BERT model\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        # Add dense layers to perform the classification\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(n_input,  n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_output)\n",
    "        )\n",
    "        # Add possibility to freeze the BERT model\n",
    "        # to avoid fine tuning BERT params (usually leads to worse results)\n",
    "        if freeze_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Feed input data to BERT\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask)\n",
    "        \n",
    "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
    "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
    "\n",
    "        # Feed input to classifier to compute logits\n",
    "        logits = self.classifier(last_hidden_state_cls)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "38410eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating function for BERT to predict\n",
    "def bert_predict(model, test_dataloader):\n",
    "    \n",
    "    # Define empty list to host the predictions\n",
    "    preds_list = []\n",
    "    \n",
    "    # Put the model into evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    for batch in test_dataloader:\n",
    "        batch_input_ids, batch_attention_mask = tuple(t.to(device) for t in batch)[:2]\n",
    "        \n",
    "        # Avoid gradient calculation of tensors by using \"no_grad()\" method\n",
    "        with torch.no_grad():\n",
    "            logit = model(batch_input_ids, batch_attention_mask)\n",
    "        \n",
    "        # Get index of highest logit\n",
    "        pred = torch.argmax(logit,dim=1).cpu().numpy()\n",
    "        # Append predicted class to list\n",
    "        preds_list.extend(pred)\n",
    "\n",
    "    return preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e55ff524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing BERT model\n",
    "bert50_model = pickle.load(open(\"D:/General Assembly/GA-projects/Capstone - Revisited/data/bert50.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1d101da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting tags on test set\n",
    "bert50_pred = bert_predict(bert50_model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "13b0c250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14341,   948,  1747],\n",
       "       [   90,   844,    11],\n",
       "       [  387,    24,  1314]], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing confusion matrix\n",
    "confusion_matrix(y, bert50_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1677c68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8556958214702586"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcuating F1-score\n",
    "bert_f1 = f1_score(y, bert50_pred, average = 'weighted')\n",
    "bert_f1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "3. Modelling - Multinomial NB and Random Forest.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
