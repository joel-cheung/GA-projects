{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "705a617f",
   "metadata": {},
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741d8524",
   "metadata": {},
   "source": [
    "Twitter is a micro-blogging social media platform with 217.5 million daily active users globally. With 500 million new tweets (posts) daily, the topics of these tweets varies widely – k-pop, politics, financial news… you name it! Individuals use it for news, entertainment, and discussions, while corporations use them to as a marketing tool to reach out to a wide audience. Given the freedom Twitter accords to its user, Twitter can provide a conducive environment for productive discourse, but this freedom can also be abused, manifesting in the forms of racism and sexism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4cfa85",
   "metadata": {},
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ca1cbd",
   "metadata": {},
   "source": [
    "With Twitter’s significant income stream coming from advertisers, it is imperative that Twitter keeps a substantial user base. On the other hand, Twitter should maintain a safe space for users and provide some level of checks for the tweets the users put out into the public space, and the first step would be to identify tweets that espouse racist or sexist ideologies, and then Twitter can direct the users to appropriate sources of information where users can learn more about the community that they offend or their subconscious biases so they will be more aware of their racist/sexist tendencies. Thus, to balance, Twitter has to be accurate in filtering inappropriate tweets from innocuous ones, and the kind of inappropriateness of flagged tweets (tag - racist or sexist).\n",
    "\n",
    "F1-scores will be the primary metric as it looks at both precision and recall, each looking at false positives (FPs) and false negatives (FNs) respectively, and is a popular metric for imbalanced data as is the case with the dataset used.\n",
    "\n",
    "For the purpose of explanation, racist tweets are used as the ‘positive’ case.\n",
    "\n",
    "In this context, FPs are the cases where the model erroneously flags out tweets as racist when the tweet is actually innocuous/sexist. FNs are cases where the model erroneously flags out tweets as innocuous/sexist but the tweets are actually racist.\n",
    "\n",
    "Thus, higher F1-scores are preferred."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a89ba68",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "95dce205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For NLP data cleaning and preprocessing\n",
    "import re, string, nltk, itertools\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import demoji\n",
    "\n",
    "# Pickle to save model\n",
    "import pickle\n",
    "\n",
    "# For NLP Machine Learning processes\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "# Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "\n",
    "# Support Vector Machine\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# PyTorch LSTM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# Tokenization for LSTM\n",
    "from collections import Counter\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Transformers library for BERT\n",
    "import transformers\n",
    "from transformers import BertModel\n",
    "from transformers import BertTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, plot_roc_curve, RocCurveDisplay\n",
    "from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix, ConfusionMatrixDisplay, classification_report, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7e3229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seed for reproducibility\n",
    "import random\n",
    "\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b54d6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing display settings\n",
    "pd.set_option('display.max_row', 100)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aadea0",
   "metadata": {},
   "source": [
    "# Importing Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cff682b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../Capstone/data/cyberbullying_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b0802e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_text', 'cyberbullying_type'], dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3990e270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47692, 2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "575f2120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In other words #katandandre, your food was crapilicious! #mkr</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is #aussietv so white? #MKR #theblock #ImACelebrityAU #today #sunrise #studio10 #Neighbours #WonderlandTen #etc</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@XochitlSuckkks a classy whore? Or more red velvet cupcakes?</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Jason_Gio meh. :P  thanks for the heads up, but not too concerned about another angry dude on twitter.</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@RudhoeEnglish This is an ISIS account pretending to be a Kurdish account.  Like Islam, it is all lies.</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                            tweet_text  \\\n",
       "0                                                        In other words #katandandre, your food was crapilicious! #mkr   \n",
       "1  Why is #aussietv so white? #MKR #theblock #ImACelebrityAU #today #sunrise #studio10 #Neighbours #WonderlandTen #etc   \n",
       "2                                                         @XochitlSuckkks a classy whore? Or more red velvet cupcakes?   \n",
       "3              @Jason_Gio meh. :P  thanks for the heads up, but not too concerned about another angry dude on twitter.   \n",
       "4              @RudhoeEnglish This is an ISIS account pretending to be a Kurdish account.  Like Islam, it is all lies.   \n",
       "\n",
       "  cyberbullying_type  \n",
       "0  not_cyberbullying  \n",
       "1  not_cyberbullying  \n",
       "2  not_cyberbullying  \n",
       "3  not_cyberbullying  \n",
       "4  not_cyberbullying  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a633590",
   "metadata": {},
   "source": [
    "# Preprocessing Test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f91bcb9",
   "metadata": {},
   "source": [
    "### Aligning tags with train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6c36ecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.loc[(test['cyberbullying_type'] == 'not_cyberbullying') |\n",
    "                (test['cyberbullying_type'] == 'ethnicity') |\n",
    "                (test['cyberbullying_type'] == 'religion') |\n",
    "                (test['cyberbullying_type'] == 'gender')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d5194a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "religion             7998\n",
       "gender               7973\n",
       "ethnicity            7961\n",
       "not_cyberbullying    7945\n",
       "Name: cyberbullying_type, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking results of filtering\n",
    "test.cyberbullying_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "323f13b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remapping flag categories - ethnicity and religion as racism (2), and gender as sexism (1)\n",
    "remap = {'ethnicity': 2, 'religion': 2, 'gender': 1, 'not_cyberbullying': 0}\n",
    "test = test.replace({'cyberbullying_type': remap})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "48a55c04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    15959\n",
       "1     7973\n",
       "0     7945\n",
       "Name: cyberbullying_type, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking results of remapping\n",
    "test.cyberbullying_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "05258fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.500643\n",
       "1    0.250118\n",
       "0    0.249239\n",
       "Name: cyberbullying_type, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.cyberbullying_type.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551d66bf",
   "metadata": {},
   "source": [
    "Due to time and memory constraints, we will only be taking a subset of this test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "805097a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = test['tweet_text'], test['cyberbullying_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c18fd59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will ensure that the there will be half of each tag will be subsetted\n",
    "X_1, X_2, y_1, y_2 = train_test_split(X, y, \n",
    "                                    train_size=0.5, \n",
    "                                    random_state= seed_value,\n",
    "                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e0cbe565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15938,)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "02a43b27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    7979\n",
       "1    3986\n",
       "0    3973\n",
       "Name: cyberbullying_type, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c7f4b6e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.500627\n",
       "1    0.250094\n",
       "0    0.249278\n",
       "Name: cyberbullying_type, dtype: float64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_1.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdc5f37",
   "metadata": {},
   "source": [
    "The proportion of y_1 has preserved the proportion of cyberbullying_type from before the train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a1a44627",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = pd.DataFrame([X_1,y_1]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "59d1672a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8876</th>\n",
       "      <td>Olly Alexander avoids going online due to homophobic ‘rape jokes’: The Years &amp;amp; Years frontman says... http://tinyurl.com/hmfmvoq #gay, #lgbt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17129</th>\n",
       "      <td>@ummahwitness @Marwan_Tunsi_ @alwallawalbara My suggestion would be that the Kuffar bomb the Kabba.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42753</th>\n",
       "      <td>bitches be mad though lmao RT @_TommyPickless: Get this cum guzzling SLORE off twitter! RT @tayyoung_: FUCK OBAMA, dumb ass nigger”</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39922</th>\n",
       "      <td>@BarackObama WOW U DUMB NIGGER&amp;lt; FUCK U AND YO HEALTH CARE NIGGA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>Yay Instant Restaurants are over!!! #mkr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                             tweet_text  \\\n",
       "8876   Olly Alexander avoids going online due to homophobic ‘rape jokes’: The Years &amp; Years frontman says... http://tinyurl.com/hmfmvoq #gay, #lgbt   \n",
       "17129                                               @ummahwitness @Marwan_Tunsi_ @alwallawalbara My suggestion would be that the Kuffar bomb the Kabba.   \n",
       "42753               bitches be mad though lmao RT @_TommyPickless: Get this cum guzzling SLORE off twitter! RT @tayyoung_: FUCK OBAMA, dumb ass nigger”   \n",
       "39922                                                                                @BarackObama WOW U DUMB NIGGER&lt; FUCK U AND YO HEALTH CARE NIGGA   \n",
       "1049                                                                                                           Yay Instant Restaurants are over!!! #mkr   \n",
       "\n",
       "      cyberbullying_type  \n",
       "8876                   1  \n",
       "17129                  2  \n",
       "42753                  2  \n",
       "39922                  2  \n",
       "1049                   0  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1008652",
   "metadata": {},
   "source": [
    "### Creating a function for text cleaning (lemmatizing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e92897ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating stopwords\n",
    "Stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f2db8d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating Stopwords to align with cleaning for train dataset\n",
    "Stopwords.update(['rt','amp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a0c5dc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_lemmatize(text):\n",
    "    # Removing emojis\n",
    "    dem = demoji.findall(text)\n",
    "    for item in dem.keys():\n",
    "        text = text.replace(item,'')\n",
    "        \n",
    "    # Removing mentions and URLs\n",
    "    pattern = re.compile(r\"(@[A-Za-z0-9]+|_[A-Za-z0-9]+|https?://\\S+|www\\.\\S+|\\S+\\.[a-z]+|)\")\n",
    "    text = pattern.sub('', text)\n",
    "    text = \" \".join(text.split())\n",
    "    \n",
    "    # Making text lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Decontracting constracted words\n",
    "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    \n",
    "    # Removing punctuations\n",
    "    remove_punc = re.compile(r\"[%s]\" % re.escape(string.punctuation))\n",
    "    text = remove_punc.sub('', text)\n",
    "    \n",
    "    # Lemmatizing\n",
    "    # To retrieve the appropriate part-of-speech (POS) tagging for each word in a sentence/tweet for the usage of WordNetLemmatizer\n",
    "    def get_wordnet_pos(word):\n",
    "        \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "        tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "        tag_dict = {\"J\": wordnet.ADJ,\n",
    "                    \"N\": wordnet.NOUN,\n",
    "                    \"V\": wordnet.VERB,\n",
    "                    \"R\": wordnet.ADV}\n",
    "        return tag_dict.get(tag, wordnet.NOUN)\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in str(text).split()]\n",
    "    text = ' '.join(text)\n",
    "    \n",
    "    # Removing back-to-back spaces\n",
    "    text = re.sub(\"\\s\\s+\" , \" \", text)\n",
    "    \n",
    "    # Removing stopwords\n",
    "    text = \" \".join([word for word in str(text).split() if word not in Stopwords])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfcaaf4",
   "metadata": {},
   "source": [
    "### Creating Function to create character n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "70111531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_char_n_gram(text, n):\n",
    "    result = []\n",
    "    text = str(text).split()\n",
    "    for word in text:\n",
    "        result.append([word[i: i + n] for i in range(len(word) - n + 1)])\n",
    "    result = list(itertools.chain.from_iterable(result))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "307ca7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results of previous function is a list of lists containing character n-grams, need to unwrap the inner lists\n",
    "def unwrapping_lists_of_char_n_grams(text):\n",
    "    for i in range(len(text)):\n",
    "        return ' '.join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06411917",
   "metadata": {},
   "source": [
    "### Cleaning and Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4458f911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning and lemmatizing\n",
    "test_1['tweet_text_lemm'] = test_1['tweet_text'].apply(lambda text: clean_text_lemmatize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d12f3d",
   "metadata": {},
   "source": [
    "### Creating character 4gram column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "23195e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a column of character 4gram\n",
    "test_1['Text_lemm_char_4_gram'] = test_1['tweet_text_lemm'].apply(lambda text: creating_char_n_gram(text,4))\n",
    "test_1['Text_lemm_char_4_gram'] = test_1['Text_lemm_char_4_gram'].apply(lambda text: unwrapping_lists_of_char_n_grams(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "eec8b57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>tweet_text_lemm</th>\n",
       "      <th>Text_lemm_char_4_gram</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8876</th>\n",
       "      <td>Olly Alexander avoids going online due to homophobic ‘rape jokes’: The Years &amp;amp; Years frontman says... http://tinyurl.com/hmfmvoq #gay, #lgbt</td>\n",
       "      <td>1</td>\n",
       "      <td>olly alexander avoids go online due homophobic ‘rape jokes’ year year frontman say gay lgbt</td>\n",
       "      <td>olly alex lexa exan xand ande nder avoi void oids onli nlin line homo omop moph opho phob hobi obic ‘rap rape joke okes kes’ year year fron ront ontm ntma tman lgbt</td>\n",
       "      <td>164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17129</th>\n",
       "      <td>@ummahwitness @Marwan_Tunsi_ @alwallawalbara My suggestion would be that the Kuffar bomb the Kabba.</td>\n",
       "      <td>2</td>\n",
       "      <td>suggestion would kuffar bomb kabba</td>\n",
       "      <td>sugg ugge gges gest esti stio tion woul ould kuff uffa ffar bomb kabb abba</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42753</th>\n",
       "      <td>bitches be mad though lmao RT @_TommyPickless: Get this cum guzzling SLORE off twitter! RT @tayyoung_: FUCK OBAMA, dumb ass nigger”</td>\n",
       "      <td>2</td>\n",
       "      <td>bitch mad though lmao get cum guzzle slore twitter fuck obama dumb nigger”</td>\n",
       "      <td>bitc itch thou houg ough lmao guzz uzzl zzle slor lore twit witt itte tter fuck obam bama dumb nigg igge gger ger”</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39922</th>\n",
       "      <td>@BarackObama WOW U DUMB NIGGER&amp;lt; FUCK U AND YO HEALTH CARE NIGGA</td>\n",
       "      <td>2</td>\n",
       "      <td>wow u dumb niggerlt fuck u yo health care nigga</td>\n",
       "      <td>dumb nigg igge gger gerl erlt fuck heal ealt alth care nigg igga</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>Yay Instant Restaurants are over!!! #mkr</td>\n",
       "      <td>0</td>\n",
       "      <td>yay instant restaurant mkr</td>\n",
       "      <td>inst nsta stan tant rest esta stau taur aura uran rant</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                             tweet_text  \\\n",
       "8876   Olly Alexander avoids going online due to homophobic ‘rape jokes’: The Years &amp; Years frontman says... http://tinyurl.com/hmfmvoq #gay, #lgbt   \n",
       "17129                                               @ummahwitness @Marwan_Tunsi_ @alwallawalbara My suggestion would be that the Kuffar bomb the Kabba.   \n",
       "42753               bitches be mad though lmao RT @_TommyPickless: Get this cum guzzling SLORE off twitter! RT @tayyoung_: FUCK OBAMA, dumb ass nigger”   \n",
       "39922                                                                                @BarackObama WOW U DUMB NIGGER&lt; FUCK U AND YO HEALTH CARE NIGGA   \n",
       "1049                                                                                                           Yay Instant Restaurants are over!!! #mkr   \n",
       "\n",
       "      cyberbullying_type  \\\n",
       "8876                   1   \n",
       "17129                  2   \n",
       "42753                  2   \n",
       "39922                  2   \n",
       "1049                   0   \n",
       "\n",
       "                                                                                   tweet_text_lemm  \\\n",
       "8876   olly alexander avoids go online due homophobic ‘rape jokes’ year year frontman say gay lgbt   \n",
       "17129                                                           suggestion would kuffar bomb kabba   \n",
       "42753                   bitch mad though lmao get cum guzzle slore twitter fuck obama dumb nigger”   \n",
       "39922                                              wow u dumb niggerlt fuck u yo health care nigga   \n",
       "1049                                                                    yay instant restaurant mkr   \n",
       "\n",
       "                                                                                                                                                      Text_lemm_char_4_gram  \\\n",
       "8876   olly alex lexa exan xand ande nder avoi void oids onli nlin line homo omop moph opho phob hobi obic ‘rap rape joke okes kes’ year year fron ront ontm ntma tman lgbt   \n",
       "17129                                                                                            sugg ugge gges gest esti stio tion woul ould kuff uffa ffar bomb kabb abba   \n",
       "42753                                                    bitc itch thou houg ough lmao guzz uzzl zzle slor lore twit witt itte tter fuck obam bama dumb nigg igge gger ger”   \n",
       "39922                                                                                                      dumb nigg igge gger gerl erlt fuck heal ealt alth care nigg igga   \n",
       "1049                                                                                                                 inst nsta stan tant rest esta stau taur aura uran rant   \n",
       "\n",
       "       text_length  \n",
       "8876         164.0  \n",
       "17129         74.0  \n",
       "42753        114.0  \n",
       "39922         64.0  \n",
       "1049          54.0  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7ead0a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1.Text_lemm_char_4_gram.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d08bef8",
   "metadata": {},
   "source": [
    "Since tweet_text_lemm texts that do not have any remaining words or that the remaining words have less than 4 characters will return a None (which does not count as NaN, dropna() will not work. Thus, there is a preliminary step to replace None with np.nan first before using dropna()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "57430c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows with None values under Text_lemm_char_4_gram column\n",
    "test_1 = test_1.replace(to_replace='None', value=np.nan).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e2d15364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1.Text_lemm_char_4_gram.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7bc3afdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15774, 5)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2ca3d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1_0s_and_1s = test_1.loc[(test_1['cyberbullying_type'] == 0) | (test_1['cyberbullying_type'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8f0e94e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3956\n",
       "0    3841\n",
       "Name: cyberbullying_type, dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1_0s_and_1s.cyberbullying_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ce98e9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = test_1_0s_and_1s['Text_lemm_char_4_gram'].values\n",
    "y1 = test_1_0s_and_1s['cyberbullying_type'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "91861f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = y1.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d52ba910",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test_1['Text_lemm_char_4_gram'].values\n",
    "y = test_1['cyberbullying_type'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7d02d29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed2fc52",
   "metadata": {},
   "source": [
    "# Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "85eefea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Naive Bayes\n",
    "multi_nb_model = pickle.load(open(\"../Capstone/multi_nb.pkl\", \"rb\"))\n",
    "\n",
    "# Random Forest\n",
    "rf_model = pickle.load(open(\"../Capstone/rf_model.pkl\", \"rb\"))\n",
    "\n",
    "# SVM\n",
    "svm_model = pickle.load(open(\"../Capstone/svm_model.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1626d0e",
   "metadata": {},
   "source": [
    "# Creating class for BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "eb5af88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "class Bert_Classifier(nn.Module):\n",
    "    def __init__(self, freeze_bert=False):\n",
    "        super(Bert_Classifier, self).__init__()\n",
    "        # Specify hidden size of BERT, hidden size of the classifier, and number of labels\n",
    "        n_input = 768\n",
    "        n_hidden = 50\n",
    "        # 3 n_output because there are 3 categories of tweets ('none': 0, 'sexism': 1, 'racism': 2)\n",
    "        n_output = 3\n",
    "        # Instantiate BERT model\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        # Add dense layers to perform the classification\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(n_input,  n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_output)\n",
    "        )\n",
    "        # Add possibility to freeze the BERT model\n",
    "        # to avoid fine tuning BERT params (usually leads to worse results)\n",
    "        if freeze_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Feed input data to BERT\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask)\n",
    "        \n",
    "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
    "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
    "\n",
    "        # Feed input to classifier to compute logits\n",
    "        logits = self.classifier(last_hidden_state_cls)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c4212d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert10_model = pickle.load(open(\"../Capstone/bert_classifier_10epochs.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582bcf93",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b321b402",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a7d96067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting tags on test set\n",
    "multi_nb_pred = multi_nb_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "37b289c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3330,  305,  206],\n",
       "       [2093, 1763,  100],\n",
       "       [4893,  611, 2473]], dtype=int64)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y, multi_nb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4afbe113",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 4947,  6986],\n",
       "        [  511,  3330]],\n",
       "\n",
       "       [[10902,   916],\n",
       "        [ 2193,  1763]],\n",
       "\n",
       "       [[ 7491,   306],\n",
       "        [ 5504,  2473]]], dtype=int64)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(y, multi_nb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8fe07e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_nb_f1 = f1_score(y, multi_nb_pred, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b3d7c6f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4803717499271705"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_nb_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6f2885a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_nb_precision = precision_score(y, multi_nb_pred, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "553cad94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6936657211406784"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_nb_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d755dcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_nb_recall = recall_score(y, multi_nb_pred, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f75f5caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4796500570559148"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_nb_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ae01af",
   "metadata": {},
   "source": [
    "As observed from this low F1-score, it can be observed that this Multinomial Naive Bayes model is overtrained to the train dataset and is not generalized well for the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6e2567",
   "metadata": {},
   "source": [
    "Since not identifying offensive tweets (False Negative) is more harmful than erroneously flagging innocuous tweets as offensive (False Positive), we can instead look at precision, i.e. proportion of positive cases that are correctly identified (innocuous tweets identified to be innocuous, racist tweets identified to be racist, and sexist tweets identified to be sexist)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
